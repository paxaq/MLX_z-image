import os
import argparse
import json
import torch
import numpy as np
import mlx.core as mx
from safetensors.torch import load_file as load_pt_file


def map_key_and_convert(key, tensor):
    # PyTorch Tensor -> Numpy (Float32)
    # BF16 ë³€í™˜ì€ ë‚˜ì¤‘ì— MLX array ìƒì„± ì‹œ ìˆ˜í–‰
    if isinstance(tensor, torch.Tensor):
        val = tensor.detach().cpu().float().numpy()
    else:
        val = tensor

    new_key = key

    # í‚¤ ë§¤í•‘ ë¡œì§ (ê¸°ì¡´ê³¼ ë™ì¼)
    if "t_embedder.mlp.0" in key:
        new_key = key.replace("t_embedder.mlp.0", "t_embedder.linear1")
    elif "t_embedder.mlp.2" in key:
        new_key = key.replace("t_embedder.mlp.2", "t_embedder.linear2")
    elif "all_x_embedder.2-1" in key:
        new_key = key.replace("all_x_embedder.2-1", "x_embedder")
    elif "cap_embedder.0" in key:
        new_key = key.replace("cap_embedder.0", "cap_embedder.layers.0")
    elif "cap_embedder.1" in key:
        new_key = key.replace("cap_embedder.1", "cap_embedder.layers.1")
    elif "all_final_layer.2-1" in key:
        new_key = key.replace("all_final_layer.2-1", "final_layer")

    if "adaLN_modulation.1" in new_key:
        new_key = new_key.replace("adaLN_modulation.1", "adaLN_modulation.layers.1")
    elif "attention.to_out.0" in key:
        new_key = key.replace("attention.to_out.0", "attention.to_out")
    elif "adaLN_modulation.0" in key and "final" not in key:
        new_key = key.replace("adaLN_modulation.0", "adaLN_modulation")
    elif "adaLN_modulation.1" in key and "final" not in key:
        new_key = key.replace("adaLN_modulation.1", "adaLN_modulation")

    # ğŸ”¥ MLX Arrayë¡œ ë³€í™˜ (BF16)
    return new_key, mx.array(val).astype(mx.bfloat16)


def main():
    parser = argparse.ArgumentParser(description="Convert Local Sharded Transformer to MLX (BF16)")
    # ë¡œì»¬ ê²½ë¡œë¥¼ ì…ë ¥ë°›ìŠµë‹ˆë‹¤.
    parser.add_argument("--src_path", type=str, default="Z-Image-Turbo/transformer",
                        help="Path to local folder containing .safetensors and index.json")
    parser.add_argument("--dest_path", type=str, default="Z-Image-Turbo-Transformer-BF16",
                        help="Output directory")
    args = parser.parse_args()

    print(f"ğŸš€ Starting Sharded Conversion: {args.src_path} -> {args.dest_path}")
    os.makedirs(args.dest_path, exist_ok=True)

    # 1. Config ë³µì‚¬
    config_src = os.path.join(args.src_path, "config.json")
    if os.path.exists(config_src):
        with open(config_src, "r") as f:
            config = json.load(f)

        # MLX í˜¸í™˜ì„± ìˆ˜ì •
        if "n_heads" in config and "nheads" not in config:
            config["nheads"] = config["n_heads"]
        config["t_scale"] = config.get("t_scale", 1000.0)

        with open(os.path.join(args.dest_path, "config.json"), "w") as f:
            json.dump(config, f, indent=4)
        print("âœ… Config copied and updated.")
    else:
        print("âš ï¸ Warning: config.json not found in source path.")

    # 2. Index íŒŒì¼ ë¡œë“œ (ë¶„í•  ì •ë³´ í™•ì¸)
    index_path = os.path.join(args.src_path, "diffusion_pytorch_model.safetensors.index.json")
    if not os.path.exists(index_path):
        # ì¸ë±ìŠ¤ íŒŒì¼ì´ ì—†ëŠ” ê²½ìš° (ë‹¨ì¼ íŒŒì¼ì¼ ìˆ˜ë„ ìˆì§€ë§Œ, ì‚¬ìš©ìê°€ 3ê°œë¼ê³  í–ˆìœ¼ë¯€ë¡œ ì—ëŸ¬ ì²˜ë¦¬)
        print(f"âŒ Error: Index file not found at {index_path}")
        print("   Make sure you are pointing to the folder containing the .index.json file.")
        return

    with open(index_path, "r") as f:
        index_data = json.load(f)

    weight_map = index_data["weight_map"]
    # ì²˜ë¦¬í•  íŒŒì¼ ëª©ë¡ ì¶”ì¶œ (ì¤‘ë³µ ì œê±° ë° ì •ë ¬)
    files_to_process = sorted(list(set(weight_map.values())))

    print(f"ğŸ“¦ Found {len(files_to_process)} shards to convert.")

    new_weight_map = {}

    # 3. íŒŒì¼ë³„ ìˆœì°¨ ë³€í™˜
    for i, filename in enumerate(files_to_process):
        src_file_path = os.path.join(args.src_path, filename)

        # íŒŒì¼ëª… ë³€í™˜ (diffusion_pytorch_model... -> model...)
        # MLX/HF í‘œì¤€ì¸ model-xxxxx-of-xxxxx.safetensors í˜•ì‹ìœ¼ë¡œ ë³€ê²½í•˜ê±°ë‚˜ ê·¸ëŒ€ë¡œ ìœ ì§€
        # ì—¬ê¸°ì„œëŠ” êµ¬ë¶„ì„ ìœ„í•´ 'model-' ì ‘ë‘ì‚¬ë¡œ í†µì¼í•©ë‹ˆë‹¤.
        dest_filename = filename.replace("diffusion_pytorch_model", "model")
        dest_file_path = os.path.join(args.dest_path, dest_filename)

        print(f"\n[{i + 1}/{len(files_to_process)}] Processing {filename} -> {dest_filename}...")

        # PyTorch ê°€ì¤‘ì¹˜ ë¡œë“œ
        pt_weights = load_pt_file(src_file_path)
        mlx_shard = {}

        # í‚¤ ë³€í™˜ ë° BF16 ìºìŠ¤íŒ…
        for k, v in pt_weights.items():
            new_k, new_v = map_key_and_convert(k, v)
            mlx_shard[new_k] = new_v

            # ìƒˆë¡œìš´ weight_map ìƒì„±ì„ ìœ„í•´ ê¸°ë¡
            new_weight_map[new_k] = dest_filename

        # ì €ì¥
        mx.save_safetensors(dest_file_path, mlx_shard)
        print(f"   âœ… Saved shard to {dest_file_path}")

        # ë©”ëª¨ë¦¬ ì •ë¦¬
        del pt_weights
        del mlx_shard
        if hasattr(mx, "clear_cache"): mx.clear_cache()

    # 4. ìƒˆë¡œìš´ Index íŒŒì¼ ìƒì„±
    new_index_data = {
        "metadata": index_data.get("metadata", {}),
        "weight_map": new_weight_map
    }

    # ì´ ì‚¬ì´ì¦ˆ ê³„ì‚° (ì„ íƒ ì‚¬í•­, ê¸°ì¡´ ë©”íƒ€ë°ì´í„° ìœ ì§€)
    with open(os.path.join(args.dest_path, "model.safetensors.index.json"), "w") as f:
        json.dump(new_index_data, f, indent=4)

    print("\nğŸ‰ All shards converted successfully!")
    print(f"   Check output at: {args.dest_path}")


if __name__ == "__main__":
    main()